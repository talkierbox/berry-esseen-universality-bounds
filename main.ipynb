{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a596f72e-24a3-46ae-b1cf-8a88b7efbcd0",
   "metadata": {},
   "source": [
    "# Project 1 — Berry–Esseen Rate for Fixed Degree _d_\n",
    "\n",
    "Empirical confirmation that the overlap  \n",
    "$$\n",
    "X_N := \\sqrt{N}\\,\\langle q, u_2\\rangle\n",
    "$$\n",
    "between a fixed test vector $q\\perp\\mathbf 1$ and the second eigenvector $u_2$ of a **random $d$-regular graph** converges to 𝒩(0, 1) at the **optimal Berry–Esseen rate**\n",
    "$$\n",
    "\\sup_x \\bigl|\\mathbb P(X_N\\le x)-\\Phi(x)\\bigr| \\;=\\; \\Theta\\!\\bigl(N^{-1/6}\\bigr),\n",
    "$$\n",
    "as established in Nagel (2025) and Huang–Yau (2023).\n",
    "\n",
    "**Credits**: This notebook was written by [Hershraj Niranjani](https://hershrajn.com)\n",
    "\n",
    "---\n",
    "\n",
    "## Experimental Design\n",
    "\n",
    "| Stage | What we do | Key parameters |\n",
    "|-------|------------|----------------|\n",
    "| **Graph generation** | Build $M \\approx 2,000$ simple $d$‑regular graphs for every $(N, d)$. | $d \\in \\{3,5,10,20\\};\\; N \\in \\{5\\,000, 10\\,000, 20\\,000, 40\\,000\\}$; `igraph.Graph.K_Regular`. |\n",
    "| **Spectral step** | Form the normalised adjacency $\\tilde A = A / \\sqrt{d-1}$ and extract $u_2$. | `scipy.sparse.linalg.eigsh` |\n",
    "| **Statistic** | Compute $X_N$ with $q = e_1 - \\dfrac{1}{N}\\mathbf 1$ (normalised). | Any deterministic $q \\perp \\mathbf 1$ works. |\n",
    "| **Distance metric** | Kolmogorov–Smirnov distance $D_N = \\sup_x \\lvert F_N(x) - \\Phi(x) \\rvert$. | Use SciPy’s `stats.kstest` or a manual CDF grid. |\n",
    "| **Rate extraction** | Linear regression of $\\log D_N$ on $\\log N$. | Slope $\\approx -1/6$ corroborates theory. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b20587f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b825d-13a9-4dd6-9eab-5028f471e2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This was ran in a python virtual environment with python version 3.13.5\n",
    "# Install the necessary dependencies\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f519ce-e7ce-47e2-94c8-5424148f1446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os \n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import scipy.sparse.linalg as spla\n",
    "from scipy.stats import kstest, norm, gaussian_kde\n",
    "import pandas as pd\n",
    "from typing import List, Sequence\n",
    "\n",
    "RANDOM_SEED = 42 # 42 for reproducibility\n",
    "\n",
    "BASE = Path(os.path.abspath(''))\n",
    "\n",
    "FIGURES = BASE / \"figures\"\n",
    "FIGURES.mkdir(exist_ok=True) # Ensure that the figures directory exists\n",
    "\n",
    "DATA = BASE / \"data\"\n",
    "DATA.mkdir(exist_ok=True) # Ensure that the data directory exists\n",
    "\n",
    "\n",
    "NUM_GRAPHS_TO_LOAD = 2_000 # Number of graphs to load in per (n, d) configuration\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1217450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graphs(file_names: Sequence[str], in_dir: str | Path) -> List[nx.Graph]:\n",
    "    \"\"\"Load .npz edge lists (saved by generate_graphs.py) into NetworkX graphs.\"\"\"\n",
    "    graphs: List[nx.Graph] = []\n",
    "    for file_name in file_names:\n",
    "        file_path = Path(in_dir) / file_name\n",
    "        data = np.load(file_path)\n",
    "        edges = data[\"edges\"]          # shape (m, 2), dtype uint32\n",
    "        g = nx.Graph()\n",
    "        g.add_edges_from(map(tuple, edges))\n",
    "        graphs.append(g)\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bb0f47",
   "metadata": {},
   "source": [
    "## Run the analysis\n",
    "Make sure that you have generated the graphs using the `generate_graphs.py` script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0426b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE         = 2_048 * 4     # tune for RAM / I/O\n",
    "N_JOBS             = max(cpu_count() - 1, 1)\n",
    "\n",
    "def _x_stat_from_file(path: Path, q: np.ndarray) -> float:\n",
    "    \"\"\"Load one .npz, build Graph, return X_N.\"\"\"\n",
    "    edges = np.load(path)[\"edges\"]\n",
    "    g = nx.Graph()\n",
    "    g.add_edges_from(map(tuple, edges))\n",
    "\n",
    "    n = g.number_of_nodes()\n",
    "    d = int(2 * g.number_of_edges() / n)\n",
    "\n",
    "    A = nx.to_scipy_sparse_array(g, dtype=float) / math.sqrt(d - 1)\n",
    "    vals, vecs = spla.eigsh(A, k=2, which=\"LM\", tol=1e-2)\n",
    "    u2 = vecs[:, np.argmax(vals) ^ 1]\n",
    "    return math.sqrt(n) * float(q @ u2)\n",
    "\n",
    "graph_files = [\n",
    "    p for d in (\"d3\", \"d5\", \"d10\", \"d20\") for p in (DATA / d).glob(\"*.npz\")\n",
    "]\n",
    "\n",
    "pat_n = re.compile(r\"_n(\\d+)\")\n",
    "groups: dict[tuple[int, int], list[Path]] = {}\n",
    "\n",
    "for p in graph_files:\n",
    "    d = int(p.parent.name[1:].lstrip(\"d\"))          # folder \"d5\" -> 5\n",
    "    n = int(pat_n.search(p.stem).group(1))\n",
    "    groups.setdefault((n, d), []).append(p)\n",
    "\n",
    "rows = []\n",
    "for (n, d), paths in sorted(groups.items()):\n",
    "    paths = paths[:NUM_GRAPHS_TO_LOAD]              # deterministic slice\n",
    "    q     = np.append([1.0], np.zeros(n - 1)) - 1.0 / n\n",
    "    q    /= np.linalg.norm(q)\n",
    "\n",
    "    X_vals = []\n",
    "    for i in range(0, len(paths), BATCH_SIZE):\n",
    "        batch = paths[i : i + BATCH_SIZE]\n",
    "        X_vals += Parallel(\n",
    "            n_jobs=N_JOBS,\n",
    "            backend=\"loky\",\n",
    "            pre_dispatch=\"2*n_jobs\"                 # keeps memory bounded\n",
    "        )(delayed(_x_stat_from_file)(p, q) for p in batch)\n",
    "\n",
    "        tqdm.write(f\"[{n=}, {d=}] processed {i + len(batch):,}/{len(paths):,}\")\n",
    "\n",
    "    D_n, _ = kstest(X_vals, norm.cdf)\n",
    "    var_n    = float(np.var(X_vals, ddof=1))            # unbiased sample variance\n",
    "    hist_y, hist_x = np.histogram(\n",
    "        X_vals, bins=\"auto\", density=True\n",
    "    ) \n",
    "    kde_x = np.linspace(min(X_vals), max(X_vals), 200)\n",
    "    kde_y = gaussian_kde(X_vals)(kde_x)\n",
    "    rows.append(\n",
    "        dict(\n",
    "            n=n,\n",
    "            d=d,\n",
    "            D_n=D_n,\n",
    "            var_n=var_n,\n",
    "            n_graphs=len(X_vals),\n",
    "            hist_x=hist_x,           # bin edges  (len = k+1)\n",
    "            hist_y=hist_y,           # densities  (len = k)\n",
    "            kde_x=kde_x,           # uncomment if you keep KDE\n",
    "            kde_y=kde_y,\n",
    "        )\n",
    "    )\n",
    "    tqdm.write(\n",
    "        f\"[n={n:,}, d={d}] D_n={D_n:.4f}, Var={var_n:.3f} from {len(X_vals):,} graphs\"\n",
    "    )\n",
    "\n",
    "print(\"All batches done.\")\n",
    "full_df = pd.DataFrame(rows)\n",
    "full_df.head(50)\n",
    "\n",
    "res_df = full_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd6ed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Berry-Esseen rate for fixed d (KS distance)\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "for d, sub in res_df.groupby(\"d\"):\n",
    "    sub = sub.sort_values(\"n\")\n",
    "\n",
    "    xs = np.log10(sub[\"n\"].values)\n",
    "    ys = np.log10(sub[\"D_n\"].clip(lower=1e-12).values)  # avoid log10(0)\n",
    "\n",
    "    # least‑squares slope on log‑log scale\n",
    "    m, b = np.polyfit(xs, ys, 1)\n",
    "    ax.plot(xs, ys, \"o-\", label=fr\"$d={d}$  slope={m:.3f}\")\n",
    "\n",
    "# reference line with slope −1/6\n",
    "N_min, N_max = res_df[\"n\"].min(), res_df[\"n\"].max()\n",
    "ref_x = np.array([N_min, N_max])\n",
    "y0 = np.log10(res_df[\"D_n\"].max())          # anchor at left edge\n",
    "ref_y = y0 - (1/6) * (np.log10(ref_x) - np.log10(N_min))\n",
    "ax.plot(np.log10(ref_x), ref_y, \"--\", color=\"gray\", lw=1.2,\n",
    "        label=r\"reference slope $-1/6$\")\n",
    "\n",
    "ax.set_xlabel(r\"$\\log_{10} N$\")\n",
    "ax.set_ylabel(r\"$\\log_{10} D_N$\")\n",
    "ax.set_title(\"Berry-Esseen rate for fixed $d$ (KS distance)\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a69d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Variance\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "for d, sub in res_df.groupby(\"d\"):\n",
    "    sub = sub.sort_values(\"n\")\n",
    "    ax.plot(\n",
    "        np.log10(sub[\"n\"]),\n",
    "        sub[\"var_n\"],\n",
    "        \"o-\",\n",
    "        label=f\"d={d}\",\n",
    "    )\n",
    "\n",
    "ax.axhline(1.0, ls=\"--\", color=\"gray\", lw=1.2, label=\"theory σ² = 1\")\n",
    "ax.set_xlabel(r\"$\\log_{10} N$\")\n",
    "ax.set_ylabel(r\"sample variance  $\\operatorname{Var}[X_N]$\")\n",
    "ax.set_title(\"Variance of $X_N$ for fixed $d$\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83bcd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the empirical density of X_N vs Standard Normal\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "for d in sorted(res_df[\"d\"].unique()):\n",
    "    row = res_df[res_df[\"d\"] == d].sort_values(\"n\").iloc[-1]  # largest N for this d\n",
    "    ax.plot(\n",
    "        row[\"kde_x\"], row[\"kde_y\"],\n",
    "        label=f\"d={d}, N={row['n']:,}\"\n",
    "    )\n",
    "\n",
    "# standard normal pdf for reference\n",
    "x_grid = np.linspace(-4, 4, 400)\n",
    "ax.plot(x_grid, norm.pdf(x_grid), \"k--\", lw=1.5, label=\"N(0, 1)\")\n",
    "\n",
    "ax.set_xlabel(r\"$x$\")\n",
    "ax.set_ylabel(\"density\")\n",
    "ax.set_title(\"Empirical density of $X_N$ vs Standard Normal\")\n",
    "ax.legend(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac418e",
   "metadata": {},
   "source": [
    "# Project 2 — Berry–Esseen Rate in the Sparse‑Growing‑Degree Regime\n",
    "\n",
    "We now let the degree grow slowly with graph size,  \n",
    "$$\n",
    "d = d(N) \\;\\le\\; N^{1/4},\n",
    "$$\n",
    "and test the refined prediction (Nagel 2025; Huang–Yau 2023) that the **rescaled KS error**\n",
    "\n",
    "$$\n",
    "\\tilde D_N \\;=\\; \\frac{D_N}{\\sqrt{d}}\n",
    "$$\n",
    "\n",
    "still obeys the optimal rate  \n",
    "\n",
    "$$\n",
    "\\tilde D_N \\;=\\; \\Theta\\!\\bigl(N^{-1/6}\\bigr).\n",
    "$$\n",
    "\n",
    "Equivalently,\n",
    "\n",
    "$$\n",
    "\\sup_x \\Bigl|\\,\\mathbb P\\!\\bigl(X_N \\le x\\bigr) - \\Phi(x)\\Bigr|\n",
    "\\;=\\;\n",
    "\\Theta\\!\\bigl(\\sqrt{d}\\,N^{-1/6}\\bigr),\n",
    "\\qquad\n",
    "X_N \\;=\\; \\sqrt{N}\\,\\langle q, u_2\\rangle.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Experimental Design\n",
    "\n",
    "| Stage | What we do | Key parameters |\n",
    "|-------|------------|----------------|\n",
    "| **Graph generation** | Build simple $d(N)$‑regular graphs with degrees that scale as powers of $N$. | $d(N) \\in \\{N^{0.00},\\, N^{0.10},\\, N^{0.25}\\}$; &nbsp;$N \\in \\{5\\,000,\\;10\\,000,\\;20\\,000,\\;40\\,000\\}$; &nbsp;≈ 50 k graphs per $(N,d)$. |\n",
    "| **Spectral step** | Form the normalised adjacency $\\tilde A = A / \\sqrt{d-1}$ and extract $u_2$. | `scipy.sparse.linalg.eigsh` |\n",
    "| **Statistic** | $X_N = \\sqrt{N}\\,\\langle q, u_2\\rangle$ with $q = e_1 - \\tfrac1N\\mathbf 1$ (normalised). | Same deterministic $q \\perp \\mathbf 1$ as in Project 1. |\n",
    "| **Distance metric** | $\\tilde D_N = D_N / \\sqrt{d}$ where $D_N$ is the KS distance between $X_N$ and $\\mathcal N(0,1)$. | `scipy.stats.kstest` |\n",
    "| **Rate extraction** | Regress $\\log_{10}\\tilde D_N$ on $\\log_{10}N$. | Slope $\\approx -1/6$ confirms universality after the $\\sqrt{d}$ factor. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d124e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "limited_df = full_df[ full_df[\"d\"] <= full_df[\"n\"] ** 0.25 ] # Ensure d(N) ≤ N^0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabe692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the scaled KS distance for growing degree d(N) ≤ N^0.25\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "# points: all (n,d) pairs, colour‑by‑d for readability\n",
    "scatter = ax.scatter(\n",
    "    np.log10(limited_df[\"n\"]),\n",
    "    np.log10(limited_df[\"D_n\"] / np.sqrt(limited_df[\"d\"])),\n",
    "    c=limited_df[\"d\"], cmap=\"viridis\", s=35\n",
    ")\n",
    "\n",
    "# global least‑squares slope in log–log space\n",
    "xs = np.log10(limited_df[\"n\"].values)\n",
    "ys = np.log10(limited_df[\"D_n\"].values / np.sqrt(limited_df[\"d\"].values))\n",
    "m, b = np.polyfit(xs, ys, 1)\n",
    "ax.plot(xs, m * xs + b, \"k--\", lw=1.5, label=f\"fit slope = {m:.3f}\")\n",
    "\n",
    "# reference – theoretical slope −1/6\n",
    "N_min, N_max = limited_df[\"n\"].min(), limited_df[\"n\"].max()\n",
    "ref_x = np.array([N_min, N_max])\n",
    "ref_y = b - (1 / 6) * (np.log10(ref_x) - np.log10(N_min))\n",
    "ax.plot(np.log10(ref_x), ref_y, \"r:\", lw=1.2, label=\"expected slope -1/6\")\n",
    "\n",
    "ax.set_xlabel(\"log10 N\")\n",
    "ax.set_ylabel(\"log10 [D_N / sqrt(d)]\")\n",
    "ax.set_title(\"Scaled KS distance for growing degree d(N) ≤ N^0.25\")\n",
    "ax.legend()\n",
    "cbar = plt.colorbar(scatter, ax=ax, label=\"degree d\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205a0d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this looks for points not covered by the bound d(N) ≤ N^0.25\n",
    "# ── Points with d(N) > N^0.25  ──────────────────────────────────────────────\n",
    "outside_df = full_df[full_df[\"d\"] > full_df[\"n\"] ** 0.25]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "# scatter: log‑log of scaled KS distance, colour by degree\n",
    "scatter = ax.scatter(\n",
    "    np.log10(outside_df[\"n\"]),\n",
    "    np.log10(outside_df[\"D_n\"] / np.sqrt(outside_df[\"d\"])),\n",
    "    c=outside_df[\"d\"],\n",
    "    cmap=\"plasma\",\n",
    "    s=35,\n",
    "    marker=\"o\",\n",
    "    label=\"outside bound\"\n",
    ")\n",
    "\n",
    "# least‑squares slope for these out‑of‑bound points\n",
    "xs = np.log10(outside_df[\"n\"].values)\n",
    "ys = np.log10(outside_df[\"D_n\"].values / np.sqrt(outside_df[\"d\"].values))\n",
    "m, b = np.polyfit(xs, ys, 1)\n",
    "ax.plot(xs, m * xs + b, \"k--\", lw=1.5, label=f\"fit slope = {m:.3f}\")\n",
    "\n",
    "# theoretical reference: slope −1/6 anchored at smallest N\n",
    "N_min, N_max = outside_df[\"n\"].min(), outside_df[\"n\"].max()\n",
    "ref_x = np.array([N_min, N_max])\n",
    "ref_y = b - (1 / 6) * (np.log10(ref_x) - np.log10(N_min))\n",
    "ax.plot(np.log10(ref_x), ref_y, \"r:\", lw=1.2, label=\"expected slope -1/6\")\n",
    "\n",
    "ax.set_xlabel(\"log10 N\")\n",
    "ax.set_ylabel(\"log10 [D_N / sqrt(d)]\")\n",
    "ax.set_title(\"Scaled KS distance for d(N) > N^0.25 (outside bound)\")\n",
    "ax.legend()\n",
    "plt.colorbar(scatter, ax=ax, label=\"degree d\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
