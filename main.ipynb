{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a596f72e-24a3-46ae-b1cf-8a88b7efbcd0",
   "metadata": {},
   "source": [
    "# Project 1 â€” Berryâ€“Esseen Rate for Fixed Degree _d_\n",
    "\n",
    "Empirical confirmation that the overlap  \n",
    "$$\n",
    "X_N := \\sqrt{N}\\,\\langle q, u_2\\rangle\n",
    "$$\n",
    "between a fixed test vector $q\\perp\\mathbf 1$ and the second eigenvector $u_2$ of a **random $d$-regular graph** converges to ð’©(0, 1) at the **optimal Berryâ€“Esseen rate**\n",
    "$$\n",
    "\\sup_x \\bigl|\\mathbb P(X_N\\le x)-\\Phi(x)\\bigr| \\;=\\; \\Theta\\!\\bigl(N^{-1/6}\\bigr),\n",
    "$$\n",
    "as established in Nagel (2025) and Huangâ€“Yau (2023).\n",
    "\n",
    "**Credits**: This notebook was written by [Hershraj Niranjani](https://hershrajn.com)\n",
    "\n",
    "---\n",
    "\n",
    "## Experimental Design\n",
    "\n",
    "| Stage | What we do | Key parameters |\n",
    "|-------|------------|----------------|\n",
    "| **Graph generation** | Build $M \\approx 7,000$ simple $d$â€‘regular graphs for every $(N, d)$ using edge-swapping Monte Carlo. | $d \\in \\{3,5,8,10\\};\\; N \\in \\{1\\,000, 10\\,000, 50\\,000\\}$; Rust backend with `3 \\times N \\times d` edge swaps per graph. |\n",
    "| **Storage format** | Save as compressed sparse CSR matrices (`.npz` files) for memory efficiency. | `scipy.sparse.save_npz` with compression; adjacency matrices stored as uint8. |\n",
    "| **Spectral step** | Form the normalised adjacency $\\tilde A = A / \\sqrt{d-1}$ and extract $u_2$. | `scipy.sparse.linalg.eigsh` with `k=2`, `which=\"LA\"`, `tol=1e-2` |\n",
    "| **Statistic** | Compute $X_N$ with $q = e_1 - \\dfrac{1}{N}\\mathbf 1$ (normalised). | Any deterministic $q \\perp \\mathbf 1$ works. |\n",
    "| **Distance metric** | Kolmogorovâ€“Smirnov distance $D_N = \\sup_x \\lvert F_N(x) - \\Phi(x) \\rvert$. | Use SciPy's `stats.kstest` with `norm.cdf` reference. |\n",
    "| **Rate extraction** | Linear regression of $\\log D_N$ on $\\log N$. | Slope $\\approx -1/6$ corroborates theory. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b20587f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "980b825d-13a9-4dd6-9eab-5028f471e2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: appnope==0.1.4 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (0.1.4)\n",
      "Requirement already satisfied: asttokens==3.0.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: comm==0.2.2 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (0.2.2)\n",
      "Requirement already satisfied: contourpy==1.3.2 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: cycler==0.12.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: debugpy==1.8.15 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 6)) (1.8.15)\n",
      "Requirement already satisfied: decorator==5.2.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 7)) (5.2.1)\n",
      "Requirement already satisfied: executing==2.2.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 8)) (2.2.0)\n",
      "Requirement already satisfied: fonttools==4.59.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 9)) (4.59.0)\n",
      "Requirement already satisfied: igraph==0.11.9 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 10)) (0.11.9)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 11)) (6.29.5)\n",
      "Requirement already satisfied: ipython==9.4.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 12)) (9.4.0)\n",
      "Requirement already satisfied: ipython_pygments_lexers==1.1.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 13)) (1.1.1)\n",
      "Requirement already satisfied: jedi==0.19.2 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 14)) (0.19.2)\n",
      "Requirement already satisfied: joblib==1.5.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 15)) (1.5.1)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 16)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.8.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 17)) (5.8.1)\n",
      "Requirement already satisfied: kiwisolver==1.4.8 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 18)) (1.4.8)\n",
      "Requirement already satisfied: llvmlite==0.44.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 19)) (0.44.0)\n",
      "Requirement already satisfied: matplotlib==3.10.3 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 20)) (3.10.3)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 21)) (0.1.7)\n",
      "Requirement already satisfied: maturin==1.9.2 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 22)) (1.9.2)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 23)) (1.6.0)\n",
      "Requirement already satisfied: networkx==3.5 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 24)) (3.5)\n",
      "Requirement already satisfied: numba==0.61.2 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 25)) (0.61.2)\n",
      "Requirement already satisfied: numpy==2.2.6 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 26)) (2.2.6)\n",
      "Requirement already satisfied: packaging==25.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 27)) (25.0)\n",
      "Requirement already satisfied: pandas==2.3.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 28)) (2.3.1)\n",
      "Requirement already satisfied: parso==0.8.4 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 29)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 30)) (4.9.0)\n",
      "Requirement already satisfied: pillow==11.3.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 31)) (11.3.0)\n",
      "Requirement already satisfied: platformdirs==4.3.8 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 32)) (4.3.8)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.51 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 33)) (3.0.51)\n",
      "Requirement already satisfied: psutil==7.0.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 34)) (7.0.0)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 35)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 36)) (0.2.3)\n",
      "Requirement already satisfied: Pygments==2.19.2 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 37)) (2.19.2)\n",
      "Requirement already satisfied: pyparsing==3.2.3 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 38)) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 39)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz==2025.2 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 40)) (2025.2)\n",
      "Requirement already satisfied: pyzmq==27.0.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 41)) (27.0.0)\n",
      "Requirement already satisfied: scipy==1.16.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 42)) (1.16.0)\n",
      "Requirement already satisfied: six==1.17.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 43)) (1.17.0)\n",
      "Requirement already satisfied: stack-data==0.6.3 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 44)) (0.6.3)\n",
      "Requirement already satisfied: texttable==1.7.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 45)) (1.7.0)\n",
      "Requirement already satisfied: tornado==6.5.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 46)) (6.5.1)\n",
      "Requirement already satisfied: tqdm==4.67.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 47)) (4.67.1)\n",
      "Requirement already satisfied: traitlets==5.14.3 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 48)) (5.14.3)\n",
      "Requirement already satisfied: tzdata==2025.2 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 49)) (2025.2)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 50)) (0.2.13)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Note: This was ran in a python virtual environment with python version 3.13.5\n",
    "# Install the necessary dependencies\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35f519ce-e7ce-47e2-94c8-5424148f1446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hershraj.niranjani/Documents/GitHub/randomgraphs-universality-bounds/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os \n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import scipy.sparse.linalg as spla\n",
    "import scipy.sparse as sp\n",
    "from scipy.stats import kstest, norm, gaussian_kde\n",
    "import pandas as pd\n",
    "from typing import List, Sequence\n",
    "\n",
    "RANDOM_SEED = 42 # 42 for reproducibility\n",
    "\n",
    "BASE = Path(os.path.abspath(''))\n",
    "\n",
    "FIGURES = BASE / \"figures\"\n",
    "FIGURES.mkdir(exist_ok=True) # Ensure that the figures directory exists\n",
    "\n",
    "DATA = BASE / \"data\"\n",
    "DATA.mkdir(exist_ok=True) # Ensure that the data directory exists\n",
    "\n",
    "\n",
    "NUM_GRAPHS_TO_LOAD = 1_00 # Number of graphs to load in per (n, d) configuration\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1217450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graphs(file_names: Sequence[str], in_dir: str | Path) -> List[nx.Graph]:\n",
    "    \"\"\"Load .npz edge lists (saved by generate_graphs.py) into NetworkX graphs.\"\"\"\n",
    "    graphs: List[nx.Graph] = []\n",
    "    for file_name in file_names:\n",
    "        file_path = Path(in_dir) / file_name\n",
    "        data = np.load(file_path)\n",
    "        edges = data[\"edges\"]          # shape (m, 2), dtype uint32\n",
    "        g = nx.Graph()\n",
    "        g.add_edges_from(map(tuple, edges))\n",
    "        graphs.append(g)\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bb0f47",
   "metadata": {},
   "source": [
    "## Run the analysis\n",
    "Make sure that you have generated the graphs using the `generate_graphs.py` script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0426b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE         = 1024\n",
    "N_JOBS             = max(cpu_count() - 1, 1)\n",
    "\n",
    "def _x_stat_from_file(path: Path, q: np.ndarray) -> float:\n",
    "    try:\n",
    "        A: sp.csr_matrix = sp.load_npz(path)\n",
    "        n = A.shape[0]\n",
    "    except (ValueError, KeyError):\n",
    "        try:\n",
    "            edges = np.load(path, mmap_mode=\"r\")[\"edges\"].astype(np.int32)\n",
    "            i, j = edges.T\n",
    "            n = i.max() + 1\n",
    "            data = np.ones(len(i), dtype=np.float32)\n",
    "            A = sp.coo_matrix(\n",
    "                (np.concatenate([data, data]),\n",
    "                (np.concatenate([i, j]), np.concatenate([j, i]))),\n",
    "                shape=(n, n),\n",
    "                dtype=np.float32,\n",
    "            ).tocsr()\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Error loading {path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    # *** make sure it's float before scaling ***\n",
    "    A = A.astype(np.float32, copy=False)\n",
    "\n",
    "    d = A.indptr[1] - A.indptr[0]          # regular degree\n",
    "    A.data *= 1.0 / np.sqrt(np.float32(d - 1))\n",
    "\n",
    "    # cast once more for eigsh (needs float64)\n",
    "    vals, vecs = spla.eigsh(A.astype(np.float64, copy=False),\n",
    "                            k=2, which=\"LA\", tol=1e-2)\n",
    "    u2 = vecs[:, 0] if vals[0] < vals[1] else vecs[:, 1]\n",
    "    return np.sqrt(n) * float(q @ u2)\n",
    "\n",
    "folders = [\"d3\", \"d5\", \"d8\", \"d10\"]\n",
    "graph_files = [\n",
    "    p for d in folders for p in (DATA / d).glob(\"*.npz\")\n",
    "]\n",
    "\n",
    "# graph_files += [\n",
    "#     p for d in [k + \"_uniform\" for k in folders] for p in (DATA / d).glob(\"*.npz\")\n",
    "# ]\n",
    "\n",
    "pat_n = re.compile(r\"_n(\\d+)\")\n",
    "groups: dict[tuple[int, int], list[Path]] = {}\n",
    "\n",
    "for p in graph_files:\n",
    "    d = int(p.parent.name[1:].lstrip(\"d\"))          # folder \"d5\" -> 5\n",
    "    n = int(pat_n.search(p.stem).group(1))\n",
    "    groups.setdefault((n, d), []).append(p)\n",
    "\n",
    "rows = []\n",
    "for (n, d), paths in sorted(groups.items()):\n",
    "    paths = paths[:NUM_GRAPHS_TO_LOAD]              # deterministic slice\n",
    "    q     = np.append([1.0], np.zeros(n - 1)) - 1.0 / n\n",
    "    q    /= np.linalg.norm(q)\n",
    "\n",
    "    X_vals = []\n",
    "\n",
    "    if n > 50_000:\n",
    "        BATCH_SIZE = 128 # reduce memory usage for large n\n",
    "\n",
    "    for i in range(0, len(paths), BATCH_SIZE):\n",
    "        batch = paths[i : i + BATCH_SIZE]\n",
    "        X_vals += Parallel(\n",
    "            n_jobs=N_JOBS,\n",
    "            backend=\"loky\",\n",
    "            pre_dispatch=\"2*n_jobs\"                 # keeps memory bounded\n",
    "        )(delayed(_x_stat_from_file)(p, q) for p in batch)\n",
    "\n",
    "        tqdm.write(f\"[{n=}, {d=}] processed {i + len(batch):,}/{len(paths):,}\")\n",
    "    X_vals = [a for a in X_vals if a is not None]  # filter out None results\n",
    "    D_n, _ = kstest(X_vals, norm.cdf)\n",
    "    var_n    = float(np.var(X_vals, ddof=1))            # unbiased sample variance\n",
    "    hist_y, hist_x = np.histogram(\n",
    "        X_vals, bins=\"auto\", density=True\n",
    "    ) \n",
    "    kde_x = np.linspace(min(X_vals), max(X_vals), 200)\n",
    "    kde_y = gaussian_kde(X_vals)(kde_x)\n",
    "    rows.append(\n",
    "        dict(\n",
    "            n=n,\n",
    "            d=d,\n",
    "            D_n=D_n,\n",
    "            var_n=var_n,\n",
    "            n_graphs=len(X_vals),\n",
    "            hist_x=hist_x,           # bin edges  (lenâ€¯=â€¯k+1)\n",
    "            hist_y=hist_y,           # densities  (lenâ€¯=â€¯k)\n",
    "            kde_x=kde_x,           # uncomment if you keep KDE\n",
    "            kde_y=kde_y,\n",
    "        )\n",
    "    )\n",
    "    tqdm.write(\n",
    "        f\"[n={n:,}, d={d}] D_n={D_n:.4f}, Var={var_n:.3f} from {len(X_vals):,} graphs\"\n",
    "    )\n",
    "\n",
    "print(\"All batches done.\")\n",
    "full_df = pd.DataFrame(rows)\n",
    "full_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db942f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "limited_df = full_df[ full_df[\"d\"] < full_df[\"n\"] ** 0.25 ] # Ensure d(N) < N^0.25\n",
    "res_df = limited_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd6ed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Visualize the Berry-Esseen rate for fixed d (KS distance)\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "for d, sub in res_df.groupby(\"d\"):\n",
    "    sub = sub.sort_values(\"n\")\n",
    "\n",
    "    xs = np.log10(sub[\"n\"].values)\n",
    "    ys = np.log10(sub[\"D_n\"].clip(lower=1e-12).values)  # avoid log10(0)\n",
    "\n",
    "    # leastâ€‘squares slope on logâ€‘log scale\n",
    "    m, b = np.polyfit(xs, ys, 1)\n",
    "    ax.plot(xs, ys, \"o-\", label=fr\"$d={d}$  slope={m:.3f}\")\n",
    "\n",
    "# reference line with slope âˆ’1/6\n",
    "N_min, N_max = res_df[\"n\"].min(), res_df[\"n\"].max()\n",
    "ref_x = np.array([N_min, N_max])\n",
    "y0 = np.log10(res_df[\"D_n\"].max())          # anchor at left edge\n",
    "ref_y = y0 - (1/6) * (np.log10(ref_x) - np.log10(N_min))\n",
    "ax.plot(np.log10(ref_x), ref_y, \"--\", color=\"gray\", lw=1.2,\n",
    "        label=r\"reference slope $-1/6$\")\n",
    "\n",
    "ax.set_xlabel(r\"$\\log_{10} N$\")\n",
    "ax.set_ylabel(r\"$\\log_{10} D_N$\")\n",
    "ax.set_title(\"Berry-Esseen rate for fixed $d$ (KS distance)\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a69d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Variance\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "for d, sub in res_df.groupby(\"d\"):\n",
    "    sub = sub.sort_values(\"n\")\n",
    "    ax.plot(\n",
    "        np.log10(sub[\"n\"]),\n",
    "        sub[\"var_n\"],\n",
    "        \"o-\",\n",
    "        label=f\"d={d}\",\n",
    "    )\n",
    "\n",
    "ax.axhline(1.0, ls=\"--\", color=\"gray\", lw=1.2, label=\"theory ÏƒÂ² = 1\")\n",
    "ax.set_xlabel(r\"$\\log_{10} N$\")\n",
    "ax.set_ylabel(r\"sample variance  $\\operatorname{Var}[X_N]$\")\n",
    "ax.set_title(\"Variance of $X_N$ for fixed $d$\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83bcd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the empirical density of X_N vs Standard Normal\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "for d in sorted(res_df[\"d\"].unique()):\n",
    "    row = res_df[res_df[\"d\"] == d].sort_values(\"n\").iloc[-1]  # largest N for this d\n",
    "    ax.plot(\n",
    "        row[\"kde_x\"], row[\"kde_y\"],\n",
    "        label=f\"d={d}, N={row['n']:,}\"\n",
    "    )\n",
    "\n",
    "# standard normal pdf for reference\n",
    "x_grid = np.linspace(-4, 4, 400)\n",
    "ax.plot(x_grid, norm.pdf(x_grid), \"k--\", lw=1.5, label=\"N(0,â€¯1)\")\n",
    "\n",
    "ax.set_xlabel(r\"$x$\")\n",
    "ax.set_ylabel(\"density\")\n",
    "ax.set_title(\"Empirical density of $X_N$ vs Standard Normal\")\n",
    "ax.legend(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac418e",
   "metadata": {},
   "source": [
    "# Project 2 â€” Berryâ€“Esseen Rate in the Sparseâ€‘Growingâ€‘Degree Regime\n",
    "\n",
    "We now let the degree grow slowly with graph size,  \n",
    "$$\n",
    "d = d(N) \\;\\le\\; N^{1/4},\n",
    "$$\n",
    "and test the refined prediction (Nagel 2025; Huangâ€“Yau 2023) that the **rescaled KS error**\n",
    "\n",
    "$$\n",
    "\\tilde D_N \\;=\\; \\frac{D_N}{\\sqrt{d}}\n",
    "$$\n",
    "\n",
    "still obeys the optimal rate  \n",
    "\n",
    "$$\n",
    "\\tilde D_N \\;=\\; \\Theta\\!\\bigl(N^{-1/6}\\bigr).\n",
    "$$\n",
    "\n",
    "Equivalently,\n",
    "\n",
    "$$\n",
    "\\sup_x \\Bigl|\\,\\mathbb P\\!\\bigl(X_N \\le x\\bigr) - \\Phi(x)\\Bigr|\n",
    "\\;=\\;\n",
    "\\Theta\\!\\bigl(\\sqrt{d}\\,N^{-1/6}\\bigr),\n",
    "\\qquad\n",
    "X_N \\;=\\; \\sqrt{N}\\,\\langle q, u_2\\rangle.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Experimental Design\n",
    "\n",
    "| Stage | What we do | Key parameters |\n",
    "|-------|------------|----------------|\n",
    "| **Graph generation** | Build simple $d(N)$â€‘regular graphs using the same edge-swapping Monte Carlo method as Project 1. | $d \\in \\{3,5,8,10\\}$ across $N \\in \\{1\\,000, 10\\,000, 50\\,000\\}$; analyze $(N,d)$ pairs satisfying $d \\leq N^{0.25}$; â‰ˆ 5k graphs per configuration. |\n",
    "| **Backend optimization** | Leverage Rust backend for fast batch generation with adaptive batch sizes based on $N$. | Batch size: 512 for $N \\leq 10k$, 256 for $N \\leq 50k$, 64 for $N > 50k$ to manage memory. |\n",
    "| **Storage format** | Same compressed sparse CSR format as Project 1 for consistent memory usage. | `scipy.sparse.save_npz` with uint8 adjacency data and int32/int64 indices based on $N$. |\n",
    "| **Spectral step** | Form the normalised adjacency $\\tilde A = A / \\sqrt{d-1}$ and extract $u_2$. | Same `scipy.sparse.linalg.eigsh` configuration as Project 1. |\n",
    "| **Statistic** | $X_N = \\sqrt{N}\\,\\langle q, u_2\\rangle$ with $q = e_1 - \\tfrac1N\\mathbf 1$ (normalised). | Same deterministic $q \\perp \\mathbf 1$ as in Project 1. |\n",
    "| **Distance metric** | $\\tilde D_N = D_N / \\sqrt{d}$ where $D_N$ is the KS distance between $X_N$ and $\\mathcal N(0,1)$. | `scipy.stats.kstest` with rescaling by $\\sqrt{d}$ |\n",
    "| **Rate extraction** | Regress $\\log_{10}\\tilde D_N$ on $\\log_{10}N$. | Slope $\\approx -1/6$ confirms universality after the $\\sqrt{d}$ factor. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabe692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the scaled KS distance for growing degree d(N) â‰¤ N^0.25\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "# points: all (n,d) pairs, colourâ€‘byâ€‘d for readability\n",
    "scatter = ax.scatter(\n",
    "    np.log10(limited_df[\"n\"]),\n",
    "    np.log10(limited_df[\"D_n\"] / np.sqrt(limited_df[\"d\"])),\n",
    "    c=limited_df[\"d\"], cmap=\"viridis\", s=35\n",
    ")\n",
    "\n",
    "# global leastâ€‘squares slope in logâ€“log space\n",
    "xs = np.log10(limited_df[\"n\"].values)\n",
    "ys = np.log10(limited_df[\"D_n\"].values / np.sqrt(limited_df[\"d\"].values))\n",
    "m, b = np.polyfit(xs, ys, 1)\n",
    "ax.plot(xs, m * xs + b, \"k--\", lw=1.5, label=f\"fit slope = {m:.3f}\")\n",
    "\n",
    "# reference â€“ theoretical slope âˆ’1/6\n",
    "N_min, N_max = limited_df[\"n\"].min(), limited_df[\"n\"].max()\n",
    "ref_x = np.array([N_min, N_max])\n",
    "ref_y = b - (1 / 6) * (np.log10(ref_x) - np.log10(N_min))\n",
    "ax.plot(np.log10(ref_x), ref_y, \"r:\", lw=1.2, label=f\"expected slope {(-1 / 6):.3f}\")\n",
    "\n",
    "ax.set_xlabel(\"log10 N\")\n",
    "ax.set_ylabel(\"log10 [D_N / sqrt(d)]\")\n",
    "ax.set_title(\"Scaled KS distance for growing degree d(N) â‰¤ N^0.25\")\n",
    "ax.legend()\n",
    "cbar = plt.colorbar(scatter, ax=ax, label=\"degree d\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205a0d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this looks for points not covered by the bound d(N) â‰¤ N^0.25\n",
    "# â”€â”€ Points with d(N) > N^0.25  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "outside_df = full_df[full_df[\"d\"] > full_df[\"n\"] ** 0.25]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "# scatter: logâ€‘log of scaled KS distance, colour by degree\n",
    "scatter = ax.scatter(\n",
    "    np.log10(outside_df[\"n\"]),\n",
    "    np.log10(outside_df[\"D_n\"] / np.sqrt(outside_df[\"d\"])),\n",
    "    c=outside_df[\"d\"],\n",
    "    cmap=\"plasma\",\n",
    "    s=35,\n",
    "    marker=\"o\",\n",
    "    label=\"outside bound\"\n",
    ")\n",
    "\n",
    "# leastâ€‘squares slope for these outâ€‘ofâ€‘bound points\n",
    "xs = np.log10(outside_df[\"n\"].values)\n",
    "ys = np.log10(outside_df[\"D_n\"].values / np.sqrt(outside_df[\"d\"].values))\n",
    "m, b = np.polyfit(xs, ys, 1)\n",
    "ax.plot(xs, m * xs + b, \"k--\", lw=1.5, label=f\"fit slope = {m:.3f}\")\n",
    "\n",
    "# theoretical reference: slope âˆ’1/6 anchored at smallest N\n",
    "N_min, N_max = outside_df[\"n\"].min(), outside_df[\"n\"].max()\n",
    "ref_x = np.array([N_min, N_max])\n",
    "ref_y = b - (1 / 6) * (np.log10(ref_x) - np.log10(N_min))\n",
    "ax.plot(np.log10(ref_x), ref_y, \"r:\", lw=1.2, label=\"expected slope -1/6\")\n",
    "\n",
    "ax.set_xlabel(\"log10 N\")\n",
    "ax.set_ylabel(\"log10 [D_N / sqrt(d)]\")\n",
    "ax.set_title(\"Scaled KS distance for d(N) > N^0.25 (outside bound)\")\n",
    "ax.legend()\n",
    "plt.colorbar(scatter, ax=ax, label=\"degree d\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
